{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:54:21.851208Z",
     "start_time": "2024-03-11T14:54:21.847576Z"
    }
   },
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import flax\n",
    "import jax, jax.numpy as jnp\n",
    "import optax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (20480, 41, 2)\n",
      "y shape (20480, 3)\n"
     ]
    }
   ],
   "source": [
    "x_samples = jnp.load('/Users/joshuacoles/Developer/checkouts/fyp/slimplectic-jax/nn/xData_lowNoise.npy').astype(\n",
    "    'float32')\n",
    "print(f\"x shape {x_samples.shape}\")\n",
    "\n",
    "y_samples = jnp.load('/Users/joshuacoles/Developer/checkouts/fyp/slimplectic-jax/nn/yData_lowNoise.npy').astype(\n",
    "    'float32')\n",
    "print(f\"y shape {y_samples.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:40:35.199558Z",
     "start_time": "2024-03-11T19:40:35.189690Z"
    }
   },
   "id": "3e704ad45a396626",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    lstm_features: int\n",
    "    action_embedding_dimension: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train):\n",
    "        print(\"Input\", x.shape)\n",
    "        # x shape should be (batch, time, features)\n",
    "        # features is x, xdot, v, vdot, t\n",
    "        carry, x = nn.RNN(nn.LSTMCell(features=self.lstm_features), return_carry=True)(x)\n",
    "        print(\"Carry\", jax.tree_util.tree_map(jnp.shape, carry))\n",
    "        print(\"After LSTM\", x.shape)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.reshape(-1)\n",
    "        print(\"After Reshape\", x.shape)\n",
    "\n",
    "        # Dropout during training\n",
    "        # x = nn.Dropout(0.3, deterministic=not train)(x)\n",
    "        # print(\"After Dropout\", x.shape)\n",
    "\n",
    "        # # Is this actually what we want or are we misunderstanding the problem\n",
    "        # x = x.reshape(x.shape[0])\n",
    "\n",
    "        x = nn.Dense(self.action_embedding_dimension)(x)\n",
    "        print(\"After Dense\", x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model(lstm_features=5, action_embedding_dimension=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:48:51.522264Z",
     "start_time": "2024-03-11T19:48:51.516735Z"
    }
   },
   "id": "7193654465da295b",
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_rngs = {'dropout': jax.random.key(1)}\n",
    "\n",
    "\n",
    "# Same as JAX version but using model.apply().\n",
    "@jax.jit\n",
    "def loss_function(params, x_batched, y_batched):\n",
    "    # Define the squared loss for a single pair (x,y)\n",
    "    def squared_error(x, y):\n",
    "        print(\"X\", x.shape)\n",
    "        print(\"Y\", y.shape)\n",
    "        pred = model.apply(params, x, train=True, rngs=loss_rngs)\n",
    "        print(\"PRED\", pred.shape)\n",
    "\n",
    "        a = jnp.inner(y - pred, y - pred) / 2.0\n",
    "        print(pred.shape)\n",
    "        print(a.shape)\n",
    "\n",
    "        return a\n",
    "\n",
    "    # Vectorize the previous to compute the average of the loss on all samples.\n",
    "    return jnp.mean(jax.vmap(squared_error)(x_batched, y_batched), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:48:52.432612Z",
     "start_time": "2024-03-11T19:48:52.428111Z"
    }
   },
   "id": "a7ea27a4d269e5cb",
   "execution_count": 178
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (41, 2)\n",
      "Carry ((5,), (5,))\n",
      "After LSTM (41, 5)\n",
      "After Reshape (205,)\n",
      "After Dense (3,)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "init_rngs = {'params': jax.random.key(0), 'dropout': jax.random.key(1)}\n",
    "params = model.init(init_rngs, jnp.ones_like(x_samples[0]), train=True)\n",
    "\n",
    "tx = optax.adam(learning_rate=learning_rate)\n",
    "opt_state = tx.init(params)\n",
    "loss_grad_fn = jax.value_and_grad(loss_function)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:50:11.928611Z",
     "start_time": "2024-03-11T19:50:11.819228Z"
    }
   },
   "id": "e3bc413713751081",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((320, 64, 41, 2), (320, 64, 3))"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "batched_x = x_samples.reshape((x_samples.shape[0] // batch_size, batch_size, x_samples.shape[1], x_samples.shape[2]))\n",
    "batched_y = y_samples.reshape((y_samples.shape[0] // batch_size, batch_size, y_samples.shape[1]))\n",
    "(batched_x.shape, batched_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:48:54.112469Z",
     "start_time": "2024-03-11T19:48:54.106899Z"
    }
   },
   "id": "d79afa1e73b270d8",
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (41, 2)\n",
      "Y (3,)\n",
      "Input (41, 2)\n",
      "Carry ((5,), (5,))\n",
      "After LSTM (41, 5)\n",
      "After Reshape (205,)\n",
      "After Dense (3,)\n",
      "PRED (3,)\n",
      "(3,)\n",
      "()\n",
      "Loss step 0:  nan\n",
      "Loss step 10:  nan\n",
      "Loss step 20:  nan\n",
      "Loss step 30:  nan\n",
      "Loss step 40:  nan\n",
      "Loss step 50:  nan\n",
      "Loss step 60:  nan\n",
      "Loss step 70:  nan\n",
      "Loss step 80:  nan\n",
      "Loss step 90:  nan\n",
      "Loss step 100:  nan\n"
     ]
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if i % 10 == 0:\n",
    "        print('Loss step {}: '.format(i), loss_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:49:29.535606Z",
     "start_time": "2024-03-11T19:48:54.812845Z"
    }
   },
   "id": "aecd5584b62e012f",
   "execution_count": 181
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"initialized parameter shapes: {jax.tree_util.tree_map(jnp.shape, flax.core.unfreeze(params))}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2df5fbd536ad6b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_val, grads = loss_grad_fn(params, x_samples, y_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:50:22.756970Z",
     "start_time": "2024-03-11T19:50:22.297029Z"
    }
   },
   "id": "9db57d55a937ee64",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'params': {'Dense_0': {'bias': Array([nan, nan, nan], dtype=float32),\n   'kernel': Array([[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]], dtype=float32)},\n  'LSTMCell_0': {'hf': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'hg': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'hi': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'ho': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'if': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'ig': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'ii': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'io': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)}}}}"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:50:28.649535Z",
     "start_time": "2024-03-11T19:50:28.636711Z"
    }
   },
   "id": "70bbdb423580b6a4",
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the squared loss for a single pair (x,y)\n",
    "def squared_error(p, x, y):\n",
    "    print(\"X\", x.shape)\n",
    "    print(\"Y\", y.shape)\n",
    "    pred = model.apply(p, x, train=False, rngs=loss_rngs)\n",
    "    delta = jnp.inner(y - pred, y - pred) / 2.0\n",
    "    print(\"PRED\", pred.shape)\n",
    "    print(\"DELTA\", delta.shape)\n",
    "\n",
    "    return delta"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:40:41.071893Z",
     "start_time": "2024-03-11T20:40:41.068617Z"
    }
   },
   "id": "eff67b3ce029bf83",
   "execution_count": 225
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (41, 2)\n",
      "Y (3,)\n",
      "Input (41, 2)\n",
      "Carry ((5,), (5,))\n",
      "After LSTM (41, 5)\n",
      "After Reshape (205,)\n",
      "After Dense (3,)\n",
      "PRED (3,)\n",
      "DELTA ()\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'params': {'Dense_0': {'bias': Array([nan, nan, nan], dtype=float32),\n   'kernel': Array([[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]], dtype=float32)},\n  'LSTMCell_0': {'hf': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'hg': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'hi': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'ho': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'if': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'ig': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'ii': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)},\n   'io': {'kernel': Array([[nan, nan, nan, nan, nan],\n           [nan, nan, nan, nan, nan]], dtype=float32)}}}}"
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda params: jnp.mean(jax.vmap(squared_error, in_axes=(None, 0, 0))(\n",
    "    params,\n",
    "    x_samples,\n",
    "    y_samples\n",
    ")))(params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:40:42.042954Z",
     "start_time": "2024-03-11T20:40:41.238913Z"
    }
   },
   "id": "3743a3a99963ac02",
   "execution_count": 226
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (41, 2)\n",
      "Y (3,)\n",
      "Input (41, 2)\n",
      "Carry ((5,), (5,))\n",
      "After LSTM (41, 5)\n",
      "After Reshape (205,)\n",
      "After Dense (3,)\n",
      "PRED (3,)\n",
      "(3,)\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": "(20480,)"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.vmap(squared_error, in_axes=(None, 0, 0))(\n",
    "    params,\n",
    "    x_samples,\n",
    "    y_samples\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:53:51.641222Z",
     "start_time": "2024-03-11T19:53:51.334975Z"
    }
   },
   "id": "543f464de98b9714",
   "execution_count": 199
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value '<generator object <genexpr> at 0x2e5932dd0>' with dtype object is not a valid JAX array type. Only arrays of numeric types are supported by JAX.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:653\u001B[0m, in \u001B[0;36mdtype\u001B[0;34m(x, canonicalize)\u001B[0m\n\u001B[1;32m    652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 653\u001B[0m   dt \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot interpret '<generator object <genexpr> at 0x2e5932dd0>' as a data type",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:2157\u001B[0m, in \u001B[0;36marray\u001B[0;34m(object, dtype, copy, order, ndmin)\u001B[0m\n\u001B[1;32m   2156\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2157\u001B[0m   dtype \u001B[38;5;241m=\u001B[39m \u001B[43mdtypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_lattice_result_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mleaves\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m leaves \u001B[38;5;28;01melse\u001B[39;00m dtypes\u001B[38;5;241m.\u001B[39mfloat_\n\u001B[1;32m   2158\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   2159\u001B[0m   \u001B[38;5;66;03m# This happens if, e.g. one of the entries is a memoryview object.\u001B[39;00m\n\u001B[1;32m   2160\u001B[0m   \u001B[38;5;66;03m# This is rare, so we only handle it if the normal path fails.\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:663\u001B[0m, in \u001B[0;36m_lattice_result_type\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_lattice_result_type\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[DType, \u001B[38;5;28mbool\u001B[39m]:\n\u001B[0;32m--> 663\u001B[0m   dtypes, weak_types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_dtype_and_weaktype\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    664\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dtypes) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:663\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_lattice_result_type\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[DType, \u001B[38;5;28mbool\u001B[39m]:\n\u001B[0;32m--> 663\u001B[0m   dtypes, weak_types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[43m_dtype_and_weaktype\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args))\n\u001B[1;32m    664\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dtypes) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:474\u001B[0m, in \u001B[0;36m_dtype_and_weaktype\u001B[0;34m(value)\u001B[0m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return a (dtype, weak_type) tuple for the given input.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28many\u001B[39m(value \u001B[38;5;129;01mis\u001B[39;00m typ \u001B[38;5;28;01mfor\u001B[39;00m typ \u001B[38;5;129;01min\u001B[39;00m _weak_types) \u001B[38;5;129;01mor\u001B[39;00m is_weakly_typed(value)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:655\u001B[0m, in \u001B[0;36mdtype\u001B[0;34m(x, canonicalize)\u001B[0m\n\u001B[1;32m    654\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot determine dtype of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dt \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m _jax_dtype_set \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m issubdtype(dt, extended):\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot determine dtype of <generator object <genexpr> at 0x2e5932dd0>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[216], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m jnp\u001B[38;5;241m.\u001B[39msum(\u001B[43mjnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleaves\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39msize\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:2162\u001B[0m, in \u001B[0;36marray\u001B[0;34m(object, dtype, copy, order, ndmin)\u001B[0m\n\u001B[1;32m   2158\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   2159\u001B[0m     \u001B[38;5;66;03m# This happens if, e.g. one of the entries is a memoryview object.\u001B[39;00m\n\u001B[1;32m   2160\u001B[0m     \u001B[38;5;66;03m# This is rare, so we only handle it if the normal path fails.\u001B[39;00m\n\u001B[1;32m   2161\u001B[0m     leaves \u001B[38;5;241m=\u001B[39m [_convert_to_array_if_dtype_fails(leaf) \u001B[38;5;28;01mfor\u001B[39;00m leaf \u001B[38;5;129;01min\u001B[39;00m leaves]\n\u001B[0;32m-> 2162\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[43mdtypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_lattice_result_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mleaves\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   2164\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m weak_type:\n\u001B[1;32m   2165\u001B[0m   dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mcanonicalize_dtype(dtype, allow_extended_dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:663\u001B[0m, in \u001B[0;36m_lattice_result_type\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_lattice_result_type\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[DType, \u001B[38;5;28mbool\u001B[39m]:\n\u001B[0;32m--> 663\u001B[0m   dtypes, weak_types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_dtype_and_weaktype\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    664\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dtypes) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    665\u001B[0m     out_dtype \u001B[38;5;241m=\u001B[39m dtypes[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:663\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_lattice_result_type\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[DType, \u001B[38;5;28mbool\u001B[39m]:\n\u001B[0;32m--> 663\u001B[0m   dtypes, weak_types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[43m_dtype_and_weaktype\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args))\n\u001B[1;32m    664\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dtypes) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    665\u001B[0m     out_dtype \u001B[38;5;241m=\u001B[39m dtypes[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:474\u001B[0m, in \u001B[0;36m_dtype_and_weaktype\u001B[0;34m(value)\u001B[0m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_dtype_and_weaktype\u001B[39m(value: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[DType, \u001B[38;5;28mbool\u001B[39m]:\n\u001B[1;32m    473\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Return a (dtype, weak_type) tuple for the given input.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 474\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28many\u001B[39m(value \u001B[38;5;129;01mis\u001B[39;00m typ \u001B[38;5;28;01mfor\u001B[39;00m typ \u001B[38;5;129;01min\u001B[39;00m _weak_types) \u001B[38;5;129;01mor\u001B[39;00m is_weakly_typed(value)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/slimplectic-jax-PUrziPqO-py3.9/lib/python3.9/site-packages/jax/_src/dtypes.py:657\u001B[0m, in \u001B[0;36mdtype\u001B[0;34m(x, canonicalize)\u001B[0m\n\u001B[1;32m    655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot determine dtype of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dt \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m _jax_dtype_set \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m issubdtype(dt, extended):\n\u001B[0;32m--> 657\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValue \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m with dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a valid JAX array \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    658\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype. Only arrays of numeric types are supported by JAX.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    659\u001B[0m \u001B[38;5;66;03m# TODO(jakevdp): fix return type annotation and remove this ignore.\u001B[39;00m\n\u001B[1;32m    660\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m canonicalize_dtype(dt, allow_extended_dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mif\u001B[39;00m canonicalize \u001B[38;5;28;01melse\u001B[39;00m dt\n",
      "\u001B[0;31mTypeError\u001B[0m: Value '<generator object <genexpr> at 0x2e5932dd0>' with dtype object is not a valid JAX array type. Only arrays of numeric types are supported by JAX."
     ]
    }
   ],
   "source": [
    "jnp.sum(jnp.array()).size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:56:17.453564Z",
     "start_time": "2024-03-11T19:56:17.188688Z"
    }
   },
   "id": "eb78d67065a08a18",
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "778"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i.size for i in jax.tree.leaves(params)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:56:26.885812Z",
     "start_time": "2024-03-11T19:56:26.881113Z"
    }
   },
   "id": "371167b5012d3f35",
   "execution_count": 218
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from slimpletic import DiscretisedSystem, GGLBundle, SolverManual\n",
    "\n",
    "q0 = jnp.array([1.0])\n",
    "pi0 = jnp.array([1.0])\n",
    "\n",
    "def lagrangian_family(q, v, _, embedding):\n",
    "    # Fixed power series expansion to make tf happy\n",
    "    v = q[0] ** 2 * embedding[0] + v[0] ** 2 * embedding[1] + q[0] * v[0] * embedding[2]\n",
    "    return v\n",
    "\n",
    "\n",
    "system = DiscretisedSystem(\n",
    "    ggl_bundle=GGLBundle(r=0),\n",
    "    dt=0.1,\n",
    "    lagrangian=lagrangian_family,\n",
    "    k_potential=None,\n",
    "    pass_additional_data=True,\n",
    ")\n",
    "\n",
    "solver = SolverManual(system)\n",
    "\n",
    "loss_rngs = {'dropout': jax.random.key(1)}\n",
    "\n",
    "\n",
    "# Same as JAX version but using model.apply().\n",
    "# @jax.jit\n",
    "def loss_function(params, x_batched, y_batched):\n",
    "    # Define the squared loss for a single pair (x,y)\n",
    "    def squared_error(trajectory, true_embedding):\n",
    "        predicted_embedding = model.apply(params, trajectory, train=True, rngs=loss_rngs)\n",
    "        \n",
    "        predicted_q, predicted_pi = solver.integrate(\n",
    "            q0=q0,\n",
    "            pi0=pi0,\n",
    "            t0=0,\n",
    "            iterations=40,\n",
    "            additional_data=predicted_embedding,\n",
    "            result_orientation='coordinate'\n",
    "        )\n",
    "\n",
    "        true_q, true_pi = solver.integrate(\n",
    "            q0=q0,\n",
    "            pi0=pi0,\n",
    "            t0=0,\n",
    "            iterations=40,\n",
    "            additional_data=true_embedding,\n",
    "            result_orientation='coordinate'\n",
    "        )\n",
    "        \n",
    "        print(\"TQ\", true_q.shape)\n",
    "        print(\"PQ\", predicted_q.shape)\n",
    "        diff = (true_q - predicted_q).reshape(-1)\n",
    "        \n",
    "        return jnp.dot(diff, diff)\n",
    "\n",
    "    # Vectorize the previous to compute the average of the loss on all samples.\n",
    "    return jnp.mean(jax.vmap(squared_error)(x_batched, y_batched), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T12:38:59.159510Z",
     "start_time": "2024-03-12T12:38:59.096808Z"
    }
   },
   "id": "be3dd11296199b4f",
   "execution_count": 239
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Array(8.07752077e+197, dtype=float64)"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(params, x_samples, y_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T12:54:30.740358Z",
     "start_time": "2024-03-12T12:54:27.347018Z"
    }
   },
   "id": "f4d90569229d343b",
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 12:51:13.710477: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 4m10.814092s\n",
      "\n",
      "********************************\n",
      "[Compiling module jit_loss_function] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n"
     ]
    },
    {
     "data": {
      "text/plain": "(Array(8.07752077e+197, dtype=float64),\n {'params': {'Dense_0': {'bias': Array([nan, nan, nan], dtype=float32),\n    'kernel': Array([[nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan],\n           [nan, nan, nan]], dtype=float32)},\n   'LSTMCell_0': {'hf': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n     'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)},\n    'hg': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n     'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)},\n    'hi': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n     'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)},\n    'ho': {'bias': Array([nan, nan, nan, nan, nan], dtype=float32),\n     'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)},\n    'if': {'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)},\n    'ig': {'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)},\n    'ii': {'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)},\n    'io': {'kernel': Array([[nan, nan, nan, nan, nan],\n            [nan, nan, nan, nan, nan]], dtype=float32)}}}})"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.value_and_grad(loss_function)(params, x_samples, y_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T12:52:31.773914Z",
     "start_time": "2024-03-12T12:45:52.539635Z"
    }
   },
   "id": "71ab7dd5be2c2f9c",
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46cc61ea85ab47b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
